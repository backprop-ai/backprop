{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning for Text Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you are new to text vectorisation be sure to look at the text vectorisation notebook first.\n",
    "\n",
    "Finetuning a text vectorisation task is mostly a matter of optimisation.\n",
    "\n",
    "Our supported text vectorisation models are applicable to multiple types of text vectorisation use cases: from detecting similar questions to finding paragraphs that contain answers to some question.\n",
    "\n",
    "However, you may be able to make your use case significantly more accurate with finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "The most value for text vectorisation comes by using your own data for finetuning.\n",
    "\n",
    "For this example, we will be using the Quora duplicate questions dataset. One row of data contains two questions and whether they are duplicate or not.\n",
    "\n",
    "Finetuning for text vectorisation uses cosine similarity to compare how similar the vectors are. Therefore, we can score duplicates as `1.0` and non duplicates as `0.0`. Any value between 0 and 1 works, but this dataset does not contain more finegrained information.\n",
    "\n",
    "Our input data will be a list of question tuples (`[(q1, q2), (q3, q4)]`) and our output data will be a list of corresponding scores (`[0.0, 1.0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (/home/kristo/.cache/huggingface/datasets/quora/default/0.0.0/2be517cf0ac6de94b77a103a36b141347a13f40637fbebaccb56ddbe397876be)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"quora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_duplicate': False,\n",
       " 'questions': {'id': [1, 2],\n",
       "  'text': ['What is the step by step guide to invest in share market in india?',\n",
       "   'What is the step by step guide to invest in share market?']}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_duplicate': True,\n",
       " 'questions': {'id': [15, 16],\n",
       "  'text': ['How can I be a good geologist?',\n",
       "   'What should I do to be a great geologist?']}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "num_positive = 0\n",
    "num_negative = 0\n",
    "\n",
    "for i in range(len(dataset[\"train\"])):\n",
    "    # Get 500 positive and 500 negative examples\n",
    "    similarity = 1.0 if dataset[\"train\"][i][\"is_duplicate\"] else 0.0\n",
    "    \n",
    "    if similarity == 1.0 and num_positive >= 500:\n",
    "        continue\n",
    "    else:\n",
    "        num_positive += 1\n",
    "        \n",
    "    if similarity == 0.0 and num_negative >= 500:\n",
    "        continue\n",
    "    else:\n",
    "        num_negative += 1\n",
    "    \n",
    "    questions = dataset[\"train\"][i][\"questions\"]\n",
    "    q1 = questions[\"text\"][0]\n",
    "    q2 = questions[\"text\"][1]\n",
    "    # Tuple\n",
    "    input_data.append((q1, q2))\n",
    "    \n",
    "    output_data.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('What is the step by step guide to invest in share market in india?',\n",
       "  'What is the step by step guide to invest in share market?'),\n",
       " 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0], output_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('How can I be a good geologist?',\n",
       "  'What should I do to be a great geologist?'),\n",
       " 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[7], output_data[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to keep the examples roughly balanced. Otherwise finetuning just makes the model more biased toward some score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "\n",
    "All we do is pass in our question pairs as input data and our similarity scores as output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Finding the optimal batch size...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch size 2 succeeded, trying batch size 4\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "Batch size 256 failed, trying batch size 128\n",
      "Finished batch size finder, will continue with full run using batch size 128\n",
      "Restored states from the checkpoint file at /home/kristo/Documents/backprop/examples/scale_batch_size_temp_model.ckpt\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type                | Params\n",
      "----------------------------------------------\n",
      "0 | model | SentenceTransformer | 135 M \n",
      "----------------------------------------------\n",
      "135 M     Trainable params\n",
      "0         Non-trainable params\n",
      "135 M     Total params\n",
      "540.511   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e8b7cf8ed341f0b86fc8381919b2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished! Save your model for later with backprop.save or upload it with backprop.upload\n"
     ]
    }
   ],
   "source": [
    "# Start a text vectorisation task with a text vectorisation model\n",
    "tv = backprop.TextVectorisation(backprop.models.DistiluseBaseMultilingualCasedV2)\n",
    "# Length here refers to number of tokens (1 token ~ 1 word)\n",
    "tv.finetune(input_data, output_data, max_input_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = tv(\"Where did Bill Gates go to school?\")\n",
    "q2 = tv(\"What school did Bill Gates go to?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043131470680237"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backprop.cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = tv(\"Where did Bill Gates go to school?\")\n",
    "q2 = tv(\"What company did Bill Gates found?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7232611179351807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backprop.cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = tv(\"Where did Bill Gates go to school?\")\n",
    "q2 = tv(\"How big is the moon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16400930285453796"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backprop.cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most similar questions get the highest score while the least similar questions get the lowest score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
