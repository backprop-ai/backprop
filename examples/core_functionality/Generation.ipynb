{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiri Core Example: Text Generation\n",
    "\n",
    "Generate text based on some provided input.\n",
    "\n",
    "The default behavior here is that of a standard instance of GPT-2 -- it'll continue writing based on whatever context you've written.\n",
    "\n",
    "Other generative models, such as T5, can be used as well. If you've trained a model, you can pass in the required tokenizer/model checkpoints and use generate for a variety of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've got one, change it here.\n",
    "api_key = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiri import Kiri\n",
    "\n",
    "if api_key:\n",
    "    kiri = Kiri(api_key=api_key)\n",
    "else:\n",
    "    kiri = Kiri(local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Geralt knew the signs: the monster was a hermit wolf. He knew the sadistic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The basic functionality, just picks up where you leave off.\n",
    "\n",
    "kiri.generate(\"Geralt knew the signs: the monster was a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplying your own checkpoints\n",
    "\n",
    "As mentioned, the default generator is GPT-2.\n",
    "\n",
    "Let's try supplying another model -- one of Kiri's pretrained T5 models. I'll be using the same model that our Sentiment Detection and Summarization modules use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admiration, approval, gratitude, pride.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The standard T5 tokenizer works fine here.\n",
    "summary_emote_model = \"kiri-ai/t5-base-qa-summary-emotion\"\n",
    "summary_emote_token = \"t5-base\"\n",
    "\n",
    "# Our sentiment function automatically adds the 'emotion:' prefix.\n",
    "# As we're accessing the generator directly, we need to do it.\n",
    "input_text = \"emotion: This is an excellent example notebook!\"\n",
    "\n",
    "kiri.generate(input_text, \n",
    "              model_name=summary_emote_model,\n",
    "              tokenizer_name=summary_emote_token,\n",
    "              do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disapproval, disgust, sadness, neutral'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we've set those models, subsequent calls will use the \n",
    "# same configuration.\n",
    "\n",
    "kiri.generate(\"emotion: My chicken was undercooked, it was awful.\",\n",
    "              do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I can\\'t find my way out of all those golems,\" I muttered, as if my voice'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likewise, we can flip back to the default...\n",
    "\n",
    "kiri.generate(\"I can't find my\",\n",
    "              model_name=\"gpt2\",\n",
    "              tokenizer_name=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the deal with all these parameters?\n",
    "\n",
    "Text generation has a *lot* of parameter options. Some tweaking may be needed for you to get optimal results for your use case. I'll cover what we make accessible by default, and how they can change generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
